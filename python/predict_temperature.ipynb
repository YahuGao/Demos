{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下载并解压数据，如下所示\n",
    "cd ~/Downloads\n",
    "mkdir jena_climate\n",
    "cd jena_climate\n",
    "wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip unzip jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 观察数据集的数据\n",
    "import os\n",
    "data_dir = '/home/yahu/demos/python/data'\n",
    "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
    "\n",
    "data = None\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解析数据, 将数据转换成Numpy数组\n",
    "import numpy as np\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header)-1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i,:] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 绘制温度时间序列\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "temp = float_data[:,1]\n",
    "plt.plot(range(len(temp), temp))\n",
    "# 每10分钟记录一个数据, 每天有144个数据点\n",
    "# 绘制前10天的温度时间序列\n",
    "plt.plot(range(1440), temp[:1440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data preprocess\n",
    "# 数据标准化 减去均值除以标准差\n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std\n",
    "\n",
    "# @data: 原始数据\n",
    "# @lookback: 包括过去多少个时间步\n",
    "# @delay: 目标应该在未来多少个时间步之后\n",
    "# @min_index, max_index: 数组中的索引, 界定需要抽取哪些时间步. 有助于划分验证集和测试集\n",
    "# @step: 数据采样的周期, 默认为6, 即每小时抽取一个数据点\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    # 预测最后一个数据要用到哪个时间步\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    # 第一个目标要用到的最大时间步\n",
    "    i = min_index + lookback\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arrange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 实例化三个生成器, 分别用于训练, 验证和测试\n",
    "lookback = 1440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step,\n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    shuffle=True,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     shuffle=True,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (300000 - 200001 - lookback) // batch_size\n",
    "test_steps = (len(float_data) - 300001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "利用黑盒深度学习模型解决问题之前, 先尝试一种基于常识的简单方法. 用它来作为合理性检查, 还可以建立一个基准, 更高级的机器学习模型需要打败这个基准才能用."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 假设温度时间序列是连续的, 且每天周期性的变化. 因此, 假设24小时后的温度等于现在的温度\n",
    "def evaluate_naive_method():\n",
    "    batch_maes = []\n",
    "    for step in range(val_steps):\n",
    "        samples, targets = next(val_gen)\n",
    "        preds = samples[:, -1, 1]\n",
    "        mae = np.mean(np.abs(preds - targets))\n",
    "        batch_maes.append(mae)\n",
    "    print(np.mean(batch_maes))\n",
    "\n",
    "evaluate_naive_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "在开始研究复杂且计算代价很好的模型之前, 先尝试使用简单且计算代价较低的机器学习模型, 比如小型的密集连接网络. 保证进一步增加问题的复杂度是合理的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(lookback // step, float_data.shape[-1])))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.draw_acc_and_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "简单的全连接方法从输入数据中删除了时间的概念. 数据是一个序列, 其中的因果关系和顺序都很重要. 下面使用一种循环序列处理模型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(32, input_shape=(None, float_data.shape[-1])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.draw_acc_and_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用循环dropout降低过拟合, 可以打破该层训练数据中的偶然相关性.\n",
    "在循环层前面使用dropout会妨碍学习过程. 循环神经网络中, 每个时间步应该使用相同的dropout掩码. 这可以让网络沿着时间步正确地传播其学习误差, 随时间随机变化的dropout掩码会破坏这个误差信号,不利于学习过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(32,\n",
    "              dropout=0.2,              # rate of inputs dropout\n",
    "              recurrent_dropout=0.2,    # rate of recurrent dropout\n",
    "              input_shape=(None, float_data.shape[-1])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)\n",
    "utils.draw_acc_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stack recurrent layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(32,\n",
    "              dropout=0.2,              # rate of inputs dropout\n",
    "              recurrent_dropout=0.2,    # rate of recurrent dropout\n",
    "              input_shape=(None, float_data.shape[-1])))\n",
    "model.add(GRU(64, activation='relu',\n",
    "              dropout=0.1,\n",
    "              recurrent_dropout=0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)\n",
    "utils.draw_acc_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将双向GRU用于温度预测任务\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(32), input_shape=(None, float_data.shape[-1])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n",
    "utils.draw_acc_and_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "更多的提高性能的方法:\n",
    "- 调节堆叠层中每层的单元个数\n",
    "- 调节优化器的学习率\n",
    "- 使用LSTM替代GRU\n",
    "- 在循环层上面使用更大的密集连接回归器, 即更大的Dense层或Dense层的堆叠\n",
    "- 在测试集上运行性能最佳的模型, 否则模型将对验证集过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "总结:\n",
    "- 建立一个基于常识的基准\n",
    "- 从简单的模型开始, 以证明增加计算代价是有意义的\n",
    "- 如果时间顺序对数据很重要, 循环网络是种很合适的方法, 一般会好过将时间数据展平的模型\n",
    "- 循环网络中的dropout应该使用不随时间变化的dropout掩码和循环dropout掩码\n",
    "- 堆叠RNN的表示能力更强, 但计算代价更高,在较简单的问题上可能不一定有用\n",
    "- 双向RNN从两个方向查看一个序列, 对NLP问题非常有用. 但如果序列数据中, 最近的数据比开头的数据包含更多的信息, 那么这种方法效果就不明显."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/yahu/anaconda3/envs/ml/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
